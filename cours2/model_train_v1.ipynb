{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"/Users/cameliamazouz/Documents/M2/machine_learning/multinli_1.0/multinli_1.0_train.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e6835f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['annotator_labels', 'genre', 'gold_label', 'pairID', 'promptID',\n",
       "       'sentence1', 'sentence1_binary_parse', 'sentence1_parse', 'sentence2',\n",
       "       'sentence2_binary_parse', 'sentence2_parse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb9328",
   "metadata": {},
   "source": [
    "#### lemmatisation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dba43220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/cameliamazouz/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/cameliamazouz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/cameliamazouz/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/cameliamazouz/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cameliamazouz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')      \n",
    "nltk.download('wordnet')    \n",
    "nltk.download('omw-1.4') \n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec6747b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemma=[]\n",
    "    for t in tokens:\n",
    "        if not(t.lower() in stop_words):\n",
    "            lemma.append(lemmatizer.lemmatize(t.lower()))\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "df[\"lemma1\"] = df[\"sentence1\"].apply(tokenize_and_lemmatize)\n",
    "df[\"lemma2\"] = df[\"sentence2\"].apply(tokenize_and_lemmatize)\n",
    "\n",
    "import re\n",
    "\n",
    "def common_words_count(s1, s2):\n",
    "    w1 = set(re.findall(r\"\\w+\", s1.lower()))\n",
    "    w2 = set(re.findall(r\"\\w+\", s2.lower()))\n",
    "    return len(w1 & w2)\n",
    "\n",
    "df['same_lemma'] = df.apply(\n",
    "    lambda row: common_words_count(row['lemma1'], row['lemma2']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Ratio de mots communs (normalisé)\n",
    "def common_words_ratio(s1, s2):\n",
    "    w1 = set(re.findall(r\"\\w+\", s1.lower()))\n",
    "    w2 = set(re.findall(r\"\\w+\", s2.lower()))\n",
    "    if len(w1) == 0 or len(w2) == 0:\n",
    "        return 0\n",
    "    return len(w1 & w2) / min(len(w1), len(w2))\n",
    "\n",
    "df['same_lemma_ratio'] = df.apply(\n",
    "    lambda row: common_words_ratio(row['lemma1'], row['lemma2']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efa592",
   "metadata": {},
   "source": [
    "#### Vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c732c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "df[\"label_id\"] = df[\"gold_label\"].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f80866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Nettoyage rapide (les NaNs font planter le vectorizer)\n",
    "df[\"sentence1\"] = df[\"sentence1\"].fillna(\"\")\n",
    "df[\"sentence2\"] = df[\"sentence2\"].fillna(\"\")\n",
    "\n",
    "# 2. Création du Vectorizer\n",
    "# On peut ajouter stop_words='english' pour virer les \"the\", \"is\", \"a\"...\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=1000) \n",
    "\n",
    "# 3. Apprentissage du vocabulaire sur TOUT le texte (S1 + S2)\n",
    "# C'est crucial pour que la colonne 42 corresponde au mot \"apple\" dans les deux vecteurs\n",
    "all_text = pd.concat([df[\"sentence1\"], df[\"sentence2\"]])\n",
    "vectorizer.fit(all_text)\n",
    "\n",
    "# 4. Transformation en vecteurs de fréquence\n",
    "# X1 = Fréquence des mots dans sentence1\n",
    "# X2 = Fréquence des mots dans sentence2 (en utilisant le même dictionnaire que S1)\n",
    "X1 = vectorizer.transform(df[\"sentence1\"])\n",
    "X2 = vectorizer.transform(df[\"sentence2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670734e",
   "metadata": {},
   "source": [
    "##### Similarite textuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a02419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Similarité cosinus entre les phrases\n",
    "def cosine_similarity_feature(s1, s2, vectorizer):\n",
    "    v1 = vectorizer.transform([s1]).toarray()[0]\n",
    "    v2 = vectorizer.transform([s2]).toarray()[0]\n",
    "    return 1 - cosine(v1, v2) if np.sum(v1) > 0 and np.sum(v2) > 0 else 0\n",
    "\n",
    "df['cosine_sim'] = df.apply(\n",
    "    lambda row: cosine_similarity_feature(row['sentence1'], row['sentence2'], vectorizer),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Ratio de longueur (au lieu de différence absolue)\n",
    "df['length_ratio'] = df['sentence1'].str.len() / (df['sentence2'].str.len() + 1)\n",
    "\n",
    "# Jaccard similarity sur les mots\n",
    "def jaccard_similarity(s1, s2):\n",
    "    w1 = set(re.findall(r\"\\w+\", s1.lower()))\n",
    "    w2 = set(re.findall(r\"\\w+\", s2.lower()))\n",
    "    if len(w1 | w2) == 0:\n",
    "        return 0\n",
    "    return len(w1 & w2) / len(w1 | w2)\n",
    "\n",
    "df['jaccard'] = df.apply(\n",
    "    lambda row: jaccard_similarity(row['sentence1'], row['sentence2']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31895ad",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81f8c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacer CountVectorizer par TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=2000, ngram_range=(1, 2))\n",
    "all_text = pd.concat([df[\"sentence1\"], df[\"sentence2\"]])\n",
    "tfidf.fit(all_text)\n",
    "\n",
    "X1_tfidf = tfidf.transform(df[\"sentence1\"])\n",
    "X2_tfidf = tfidf.transform(df[\"sentence2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62fb0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# On choisit l'index que tu voulais (1)\n",
    "idx = 1\n",
    "\n",
    "# 1. Récupérer le dictionnaire (la liste des mots dans l'ordre des colonnes)\n",
    "vocabulaire = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 2. Récupérer les comptes pour la ligne choisie\n",
    "# .flatten() permet d'aplatir le tableau (convertir [[0,1]] en [0,1])\n",
    "compte_s1 = X1[idx].toarray().flatten()\n",
    "compte_s2 = X2[idx].toarray().flatten()\n",
    "\n",
    "# 3. Créer un tableau propre pour l'affichage\n",
    "df_visu = pd.DataFrame({\n",
    "    'Mot': vocabulaire,\n",
    "    'S1 (Freq)': compte_s1,\n",
    "    'S2 (Freq)': compte_s2\n",
    "})\n",
    "\n",
    "# 4. FILTRAGE : On n'affiche que les mots présents dans au moins l'une des phrases\n",
    "# (Sinon on va afficher 990 lignes de zéros)\n",
    "mask = (df_visu['S1 (Freq)'] > 0) | (df_visu['S2 (Freq)'] > 0)\n",
    "df_resultat = df_visu[mask].sort_values(by='S1 (Freq)', ascending=False)\n",
    "\n",
    "# --- AFFICHAGE ---\n",
    "# print(f\"--- Analyse de l'index {idx} ---\\n\")\n",
    "# print(f\"Phrase 1 : \\\"{df['sentence1'].iloc[idx]}\\\"\")\n",
    "# print(f\"Phrase 2 : \\\"{df['sentence2'].iloc[idx]}\\\"\\n\")\n",
    "# print(\"Mots comptés (intersection avec le vocabulaire connu) :\")\n",
    "# print(df_resultat.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144b6ae",
   "metadata": {},
   "source": [
    "##### Features lexi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d657bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_ratio(s1, s2):\n",
    "    w1 = set(s1.split())\n",
    "    w2 = set(s2.split())\n",
    "    return len(w1 & w2) / min(len(w1), len(w2)) if min(len(w1), len(w2)) > 0 else 0\n",
    "df['overlap_ratio'] = df.apply(\n",
    "    lambda row: overlap_ratio(row['lemma1'], row['lemma2']),\n",
    "    axis=1)\n",
    "\n",
    "def common_ratio(s1, s2):\n",
    "    w1 = set(s1.split())\n",
    "    w2 = set(s2.split())\n",
    "    common = len(w1 & w2)\n",
    "    return common / ((len(w1) + len(w2)) / 2) if (len(w1) + len(w2)) / 2 > 0 else 0\n",
    "df['common_ratio'] = df.apply(\n",
    "    lambda row: common_ratio(row['lemma1'], row['lemma2']),\n",
    "    axis=1)\n",
    "neg_words = {'no','not','never','none','nothing','nobody','without'}\n",
    "\n",
    "def neg_count(s):\n",
    "    return sum(1 for w in s.split() if w in neg_words)\n",
    "\n",
    "df['neg1'] = df['lemma1'].apply(neg_count)\n",
    "df['neg2'] = df['lemma2'].apply(neg_count)\n",
    "df['neg_diff'] = abs(df['neg1'] - df['neg2'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66eeaf9",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd204c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import hstack\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import re\n",
    "\n",
    "# # Créer les features dif et same\n",
    "# df[\"dif\"] = (\n",
    "#     df['sentence1'].str.len() -\n",
    "#     df['sentence2'].str.len()\n",
    "# ).abs()\n",
    "\n",
    "# def common_words_count(s1, s2):\n",
    "#     w1 = set(re.findall(r\"\\w+\", s1.lower()))\n",
    "#     w2 = set(re.findall(r\"\\w+\", s2.lower()))\n",
    "#     return len(w1 & w2)\n",
    "\n",
    "# df['same'] = df.apply(\n",
    "#     lambda row: common_words_count(row['sentence1'], row['sentence2']),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "\n",
    "# # Nouvelles features à ajouter\n",
    "# new_features = ['cosine_sim', 'length_ratio', 'jaccard', \n",
    "#                  'same_lemma_ratio']\n",
    "\n",
    "# X_combined = hstack([\n",
    "#     X1_tfidf, \n",
    "#     X2_tfidf, \n",
    "#     df[['dif'] + new_features].values\n",
    "# ])\n",
    "\n",
    "# y = df[\"label_id\"]\n",
    "\n",
    "# print(f\"Split des données (10% test sur {len(df)} lignes)...\")\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_combined, y, test_size=0.10, random_state=42\n",
    "# )\n",
    "\n",
    "# # 6. ENTRAÎNEMENT (Régression Logistique)\n",
    "# print(\"Entraînement du modèle...\")\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # 7. ÉVALUATION\n",
    "# predictions = model.predict(X_test)\n",
    "# acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "# print(f\"\\n--- RÉSULTATS ---\")\n",
    "# print(f\"Accuracy (Précision globale) : {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "# # Détail par classe\n",
    "# target_names = [\"Entailment (0)\", \"Neutral (1)\", \"Contradiction (2)\"]\n",
    "# print(\"\\nDétail par classe :\")\n",
    "# print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92573a39",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split des données (10% test sur 1000 lignes)...\n",
      "Entraînement du modèle SVM...\n",
      "\n",
      "--- RÉSULTATS ---\n",
      "Accuracy (Précision globale) : 0.4200 (42.00%)\n",
      "\n",
      "Détail par classe :\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   Entailment (0)       0.47      0.55      0.51        31\n",
      "      Neutral (1)       0.39      0.31      0.35        29\n",
      "Contradiction (2)       0.39      0.40      0.40        40\n",
      "\n",
      "         accuracy                           0.42       100\n",
      "        macro avg       0.42      0.42      0.42       100\n",
      "     weighted avg       0.42      0.42      0.42       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "\n",
    "# Créer les features dif et same\n",
    "df[\"dif\"] = (\n",
    "    df['sentence1'].str.len() -\n",
    "    df['sentence2'].str.len()\n",
    ").abs()\n",
    "\n",
    "def common_words_count(s1, s2):\n",
    "    w1 = set(re.findall(r\"\\w+\", s1.lower()))\n",
    "    w2 = set(re.findall(r\"\\w+\", s2.lower()))\n",
    "    return len(w1 & w2)\n",
    "\n",
    "df['same'] = df.apply(\n",
    "    lambda row: common_words_count(row['sentence1'], row['sentence2']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "new_features = ['cosine_sim', 'length_ratio', 'jaccard', \n",
    "                 'same_lemma_ratio','neg1','neg2','neg_diff']\n",
    "\n",
    "X_combined = hstack([\n",
    "    X1_tfidf, \n",
    "    X2_tfidf, \n",
    "    df[['dif'] + new_features].values\n",
    "])\n",
    "\n",
    "y = df[\"label_id\"]\n",
    "\n",
    "print(f\"Split des données (10% test sur {len(df)} lignes)...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_combined, y, test_size=0.10, random_state=42\n",
    ")\n",
    "\n",
    "# 6. ENTRAÎNEMENT (SVM)\n",
    "print(\"Entraînement du modèle SVM...\")\n",
    "model = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 7. ÉVALUATION\n",
    "predictions = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"\\n--- RÉSULTATS ---\")\n",
    "print(f\"Accuracy (Précision globale) : {acc:.4f} ({acc*100:.2f}%)\")\n",
    "\n",
    "# Détail par classe\n",
    "target_names = [\"Entailment (0)\", \"Neutral (1)\", \"Contradiction (2)\"]\n",
    "print(\"\\nDétail par classe :\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
